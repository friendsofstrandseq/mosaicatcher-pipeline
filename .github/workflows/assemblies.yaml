name: MosaiCatcher assemblies checks

on:
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      logLevel:
        description: "Log level"
        required: true
        default: "warning"
        type: choice
        options:
          - info
          - warning
          - debug

jobs:
  test-assembly:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          - genome: hg38
            url: "https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/analysisSet/hg38.analysisSet.fa.gz"
            chromosome: "chr17"
            ashleys_pipeline: "False"
            hgsvc_based_normalized_counts: "True"
            ploidy: "True"
            data_location: ".tests/data_CHR17"
            extra_args: ""

          - genome: hg19
            url: "https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/analysisSet/hg19.p13.plusMT.no_alt_analysis_set.fa.gz"
            chromosome: "chr17"
            ashleys_pipeline: "True"
            hgsvc_based_normalized_counts: "False"
            ploidy: "True"
            data_location: ".tests/data_CHR17"
            extra_args: ""

          - genome: T2T
            url: "https://s3-us-west-2.amazonaws.com/human-pangenomics/T2T/CHM13/assemblies/analysis_set/chm13v2.0.fa.gz"
            chromosome: "chr17"
            ashleys_pipeline: "True"
            hgsvc_based_normalized_counts: "False"
            ploidy: "True"
            data_location: ".tests/data_CHR17"
            extra_args: "--retries 3 --latency-wait 60"

          - genome: mm10
            url: "https://hgdownload.soe.ucsc.edu/goldenPath/mm10/bigZips/mm10.fa.gz"
            chromosome: "chr19"
            ashleys_pipeline: "True"
            hgsvc_based_normalized_counts: "False"
            ploidy: "False"
            data_location: ".tests/data_chr19_mm"
            extra_args: ""

          - genome: mm39
            url: "https://hgdownload.soe.ucsc.edu/goldenPath/mm39/bigZips/mm39.fa.gz"
            chromosome: "chr19"
            ashleys_pipeline: "True"
            hgsvc_based_normalized_counts: "False"
            ploidy: "False"
            data_location: ".tests/data_chr19_mm"
            extra_args: ""

    name: Test ${{ matrix.genome }}
    steps:
      - name: Checkout repository with submodules
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Git Submodule Update
        run: |
          git submodule update --recursive --init

      - name: Setup Pixi
        uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: latest
          cache: true
          locked: false

      - name: Restore Conda environments cache
        id: cache-conda-restore
        uses: actions/cache/restore@v4
        with:
          path: .snakemake/conda
          key: conda-envs-${{ hashFiles('workflow/envs/*.yaml') }}
          restore-keys: |
            conda-envs-

      - name: Restore ${{ matrix.genome }} reference genome and BWA indexes
        id: cache-reference-restore
        uses: actions/cache/restore@v4
        with:
          path: |
            workflow/data/ref_genomes/${{ matrix.genome }}.fa
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.amb
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.ann
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.bwt
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.pac
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.sa
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.fai
          key: ${{ matrix.genome }}-reference-v1
          restore-keys: |
            ${{ matrix.genome }}-reference-

      - name: Download and index ${{ matrix.genome }} reference (if not cached)
        if: steps.cache-reference-restore.outputs.cache-hit != 'true'
        run: |
          # Install tools
          sudo apt-get update && sudo apt-get install -y bwa samtools

          # Download reference
          mkdir -p workflow/data/ref_genomes
          echo "Downloading ${{ matrix.genome }} reference genome..."
          wget -q -O ${{ matrix.genome }}.fa.gz "${{ matrix.url }}"
          gunzip -c ${{ matrix.genome }}.fa.gz > workflow/data/ref_genomes/${{ matrix.genome }}.fa
          rm ${{ matrix.genome }}.fa.gz

          # Build indexes
          echo "Building BWA index..."
          bwa index workflow/data/ref_genomes/${{ matrix.genome }}.fa
          echo "Building samtools faidx..."
          samtools faidx workflow/data/ref_genomes/${{ matrix.genome }}.fa

          echo "Reference preparation complete:"
          ls -lh workflow/data/ref_genomes/${{ matrix.genome }}.fa*

      - name: Save ${{ matrix.genome }} reference cache (after indexing)
        if: steps.cache-reference-restore.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: |
            workflow/data/ref_genomes/${{ matrix.genome }}.fa
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.amb
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.ann
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.bwt
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.pac
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.sa
            workflow/data/ref_genomes/${{ matrix.genome }}.fa.fai
          key: ${{ matrix.genome }}-reference-v1

      - name: Run workflow (${{ matrix.genome }})
        run: |
          pixi run snakemake \
            --cores 1 \
            --sdm conda \
            --local-storage-prefix $GITHUB_WORKSPACE \
            --config reference=${{ matrix.genome }} data_location=${{ matrix.data_location }} use_light_data=True chromosomes=[${{ matrix.chromosome }}] ashleys_pipeline=${{ matrix.ashleys_pipeline }} hgsvc_based_normalized_counts=${{ matrix.hgsvc_based_normalized_counts }} ploidy=${{ matrix.ploidy }} \
            --conda-cleanup-pkgs cache \
            ${{ matrix.extra_args }} \
            -p \
            --snakefile workflow/Snakefile

      - name: Save Conda environments cache
        if: always()
        uses: actions/cache/save@v4
        with:
          path: .snakemake/conda
          key: conda-envs-${{ hashFiles('workflow/envs/*.yaml') }}
